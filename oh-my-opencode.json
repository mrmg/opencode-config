{
  "$schema": "https://raw.githubusercontent.com/code-yeongyu/oh-my-opencode/master/assets/oh-my-opencode.schema.json",

  "agents": {
    "__comment_kato": "==================== KATO (HUGE MATURE CODEBASE) - COST OPTIMIZED 2026-01-06 ====================",
    "__comment_kato_path": "Path: /home/mrmg/Development/Kato/** - Cost: ~$40/mo (was ~$780!) - Performance: 70-80% SWE-bench",
    "__comment_savings": "95% cost reduction: Haiku 4.5 ($1/$5, 73.3% SWE, 90% of Sonnet 4.5!) and Gemini Flash ($0.30) replace Sonnet ($15) and GPT-5.2 ($15)",
    "__comment_haiku45": "Haiku 4.5 released Oct 2025: 73.3% SWE, extended thinking, 2x faster than Sonnet 4.5, $1/$5 per 1M",

    "Sisyphus": {
      "model": "github-copilot/claude-haiku-4.5",
      "temperature": 0.3,
      "description": "Kato: Haiku 4.5 - 73.3% SWE, 90% of Sonnet 4.5, 2x faster, $1/$5 per 1M!"
    },

    "Planner-Sisyphus": {
      "model": "github-copilot/claude-haiku-4.5",
      "temperature": 0.3,
      "description": "Kato: Haiku 4.5 - Extended thinking, 90% of Sonnet 4.5 at 1/3 cost!"
    },

    "Builder-Sisyphus": {
      "model": "github-copilot/claude-haiku-4.5",
      "temperature": 0.2,
      "description": "Kato: Haiku 4.5 - Fast implementation with extended thinking, $1/$5 per 1M!"
    },

    "oracle": {
      "model": "google/gemini-3-pro-preview",
      "temperature": 0.2,
      "description": "Kato: Strategic reasoning (Gemini Pro: 14x cheaper than GPT-5.2! $0.35/$1.05 per 1M)"
    },

    "librarian": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.1,
      "description": "Kato: Fast research (Gemini 3 Flash: 76% SWE, newest Flash model!)"
    },

    "explore": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.0,
      "description": "Kato: FAST 1M context exploration (Gemini 3 Flash: 76% SWE, newest!)"
    },

    "codebase-analyzer": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.1,
      "mode": "subagent",
      "description": "Kato: Analyze huge codebase sections (Gemini 3 Flash: 76% SWE, 1M context)",
      "tools": ["read", "glob", "grep", "lsp_*", "session_*"]
    },

    "frontend-ui-ux-engineer": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.7,
      "description": "Kato: Creative UI (Gemini 3 Flash: 76% SWE, 1M context)"
    },

    "document-writer": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.5,
      "description": "Kato: Fast docs (Gemini 3 Flash: 1M context)"
    },

    "multimodal-looker": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.2,
      "description": "Kato: Multimodal (Gemini 3 Flash: 1M context)"
    },

    "test-engineer": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Kato: Test generation (Gemini 3 Flash: 76% SWE)"
    },

    "debugger": {
      "model": "google/gemini-3-pro-preview",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Kato: Debugging after 2+ failures (Gemini Pro: 14x cheaper than GPT-5.2!)"
    },

    "refactorer": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Kato: Quick refactoring (Gemini 3 Flash: 76% SWE)"
    },

    "security-auditor": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.1,
      "mode": "subagent",
      "description": "Kato: Security review (Gemini 3 Flash: 76% SWE)"
    },

    "performance-optimizer": {
      "model": "google/gemini-3-pro-preview",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Kato: Performance optimization (Gemini Pro: 14x cheaper than GPT-5.2!)"
    },

    "database-architect": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Kato: DB design (Gemini 3 Flash: 76% SWE)"
    },

    "devops-engineer": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.3,
      "mode": "subagent",
      "description": "Kato: DevOps (Gemini 3 Flash: fast and powerful)"
    },

    "migration-specialist": {
      "model": "github-copilot/claude-opus-4.5",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Kato: Legacy migrations need Opus precision (KEEP - complex migrations worth premium cost!)"
    },

    "api-designer": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.3,
      "mode": "subagent",
      "description": "Kato: API design (Gemini 3 Flash: 76% SWE)"
    },

    "reviewer": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Kato: Code review (Gemini 3 Flash: 76% SWE)"
    },

    "qa-specialist": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.3,
      "mode": "subagent",
      "description": "Kato: QA planning (Gemini 3 Flash: 76% SWE)"
    },

    "premium-fallback": {
      "model": "github-copilot/gpt-4o",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Kato: Premium fallback when Haiku/Flash insufficient (via GitHub Copilot)"
    },

    "__comment_personal": "==================== PERSONAL (SMALL GREENFIELD) - Max Value (NO CHANGES NEEDED) ====================",
    "__comment_personal_path": "Path: /home/mrmg/Development/Personal/** - Cost: FREE - Performance: 72-74% SWE-bench",
    "__comment_personal_updated": "Already optimized using FREE models (MiniMax M2.1, GLM-4.7, Grok Code)",

    "Sisyfreeus": {
      "model": "opencode/minimax-m2.1-free",
      "temperature": 0.3,
      "mode": "primary",
      "description": "Personal: PRIMARY CODER - 74% SWE-bench (HIGHEST!), 66.9 tok/s"
    },

    "Planner-Sisyfreeus": {
      "model": "opencode/glm-4.7-free",
      "temperature": 0.2,
      "mode": "primary",
      "description": "Personal: ARCHITECT - 73.8% SWE + 95.7% AIME (best reasoning)"
    },

    "Builder-Sisyfreeus": {
      "model": "opencode/minimax-m2.1-free",
      "temperature": 0.2,
      "mode": "primary",
      "description": "Personal: BUILDER - 74% SWE-bench, fastest among top performers"
    },

    "orchestrator-free": {
      "model": "opencode/glm-4.7-free",
      "temperature": 0.3,
      "mode": "subagent",
      "description": "Personal: ORCHESTRATOR - GLM-4.7 (73.8% SWE, FREE via OpenCode)"
    },

    "rapid-coder-free": {
      "model": "opencode/grok-code",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Personal: SPEED DEMON - 70.8% SWE, 296 tok/s, perfect for quick edits"
    },

    "oracle-free": {
      "model": "google/gemini-3-pro-preview",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Personal: STRATEGIC REASONING - Gemini 3 Pro (76.2% SWE, $0.35/$1.05 per 1M - cheap!)"
    },

    "reasoner-free": {
      "model": "opencode/glm-4.7-free",
      "temperature": 0.1,
      "mode": "subagent",
      "description": "Personal: Elite reasoning (73.8% SWE + 95.7% AIME, GLM-4.7 FREE)"
    },

    "librarian-free": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.1,
      "mode": "subagent",
      "description": "Personal: Fast research (Gemini 3 Flash: 76% SWE)"
    },

    "large-context-free": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Personal: LARGE CONTEXT - 1M tokens, Gemini 3 Flash (76% SWE)"
    },

    "backup-coder-free": {
      "model": "opencode/minimax-m2.1-free",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Personal: BACKUP - MiniMax M2.1 (74% SWE, FREE, fast)"
    },

    "experimental-free": {
      "model": "opencode/big-pickle",
      "temperature": 0.3,
      "mode": "subagent",
      "description": "Personal: GLM-4.6 (68% SWE, 82.8% LiveCodeBench) - Good but GLM-4.7 is better"
    },

    "explore-free": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.0,
      "mode": "subagent",
      "description": "Personal: Blazing fast with 1M context! (Gemini 3 Flash: 76% SWE)"
    },

    "frontend-free": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.7,
      "mode": "subagent",
      "description": "Personal: Fast creative UI (Gemini 3 Flash: 76% SWE, 1M context)"
    },

    "document-writer-free": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.5,
      "mode": "subagent",
      "description": "Personal: Fast docs (Gemini 3 Flash: 1M context)"
    },

    "multimodal-looker-free": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Personal: Multimodal (Gemini 3 Flash: 1M context)"
    },

    "test-engineer-free": {
      "model": "opencode/glm-4.7-free",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Personal: FREE test generation (73.8% SWE, GLM-4.7 excellent reasoning)"
    },

    "debugger-free": {
      "model": "opencode/grok-code",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Personal: FAST debugging (70.8% SWE, 296 tok/s, terminal fluency)"
    },

    "refactorer-free": {
      "model": "opencode/glm-4.7-free",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Personal: FREE refactoring (73.8% SWE, GLM-4.7 high quality!)"
    },

    "security-auditor-free": {
      "model": "opencode/glm-4.7-free",
      "temperature": 0.1,
      "mode": "subagent",
      "description": "Personal: Security analysis (73.8% SWE, GLM-4.7 FREE)"
    },

    "performance-optimizer-free": {
      "model": "opencode/glm-4.7-free",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Personal: Performance optimization (73.8% SWE, GLM-4.7 FREE)"
    },

    "database-architect-free": {
      "model": "opencode/glm-4.7-free",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Personal: FREE DB design (73.8% SWE + superior reasoning)"
    },

    "devops-engineer-free": {
      "model": "opencode/grok-code",
      "temperature": 0.3,
      "mode": "subagent",
      "description": "Personal: FREE DevOps (70.8% SWE, terminal fluency, fast)"
    },

    "migration-specialist-free": {
      "model": "opencode/glm-4.7-free",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Personal: FREE migrations (73.8% SWE, multi-file orchestration)"
    },

    "api-designer-free": {
      "model": "opencode/glm-4.7-free",
      "temperature": 0.3,
      "mode": "subagent",
      "description": "Personal: FREE API design (73.8% SWE, polished output)"
    },

    "data-engineer-free": {
      "model": "opencode/glm-4.7-free",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Personal: FREE data modeling (73.8% SWE, GLM-4.7 excellent reasoning)"
    },

    "accessibility-specialist-free": {
      "model": "google/gemini-3-flash-preview",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Personal: WCAG compliance (Gemini 3 Flash: 76% SWE)"
    },

    "rapid-prototyper-free": {
      "model": "opencode/glm-4.7-free",
      "temperature": 0.5,
      "mode": "subagent",
      "description": "Personal: Fast MVPs (73.8% SWE, GLM-4.7 FREE!)"
    },

    "reviewer-free": {
      "model": "opencode/glm-4.7-free",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Personal: FREE code review (73.8% SWE + superior reasoning)"
    },

    "qa-specialist-free": {
      "model": "opencode/glm-4.7-free",
      "temperature": 0.3,
      "mode": "subagent",
      "description": "Personal: FREE QA planning (73.8% SWE, GLM-4.7 excellent reasoning)"
    }
  },

  "sisyphus_agent": {
    "disabled": false,
    "default_builder_enabled": true,
    "planner_enabled": true,
    "replace_plan": true
  }
}
