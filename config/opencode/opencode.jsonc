// ============================================================================
// CONSOLIDATED OPENCODE CONFIGURATION
// ============================================================================
// Single source of truth for all agent configurations
// Naming convention: lowercase-kebab-case
// Model format: use dashes consistently (e.g., claude-opus-4-5, not 4.5)
// ============================================================================

{
  "$schema": "https://opencode.ai/config.json",
  "theme": "opencode",
  "model": "kato-coder",
  "autoupdate": true,

  // ============================================================================
  // PRIMARY AGENTS - WORK (Kato - Anthropic via OpenCode)
  // ============================================================================
  "agent": {
    // Work Primary Agents
    "kato-architect": {
      "model": "opencode/claude-opus-4-5",
      "temperature": 0.2,
      "mode": "primary",
      "description": "Kato: Architecture & Design - Claude Opus 4.5 (80.9% SWE-bench)"
    },
    
    "kato-coder": {
      "model": "opencode/claude-sonnet-4-5",
      "temperature": 0.2,
      "mode": "primary",
      "description": "Kato: Implementation - Claude Sonnet 4.5 (77.2% SWE-bench)"
    },
    
    "kato-strategist": {
      "model": "opencode/claude-opus-4-5",
      "temperature": 0.2,
      "mode": "primary",
      "description": "Kato: Strategic Planning - Claude Opus 4.5"
    },
    
    "kato-typescript": {
      "model": "opencode/kimi-k2.5",
      "temperature": 0.2,
      "mode": "primary",
      "description": "Kato: TypeScript & React specialist - Kimi K2.5 (Moonshot AI) rivals Claude Opus 4.5"
    },

    // ============================================================================
    // PRIMARY AGENTS - PERSONAL
    // ============================================================================
    
    "personal-architect": {
      "model": "opencode/gpt-5.2",
      "temperature": 0.2,
      "mode": "primary",
      "description": "Personal: Architecture & Design - GPT-5.2 (80% SWE-bench)"
    },
    
    "personal-coder": {
      "model": "opencode/claude-sonnet-4-5",
      "temperature": 0.2,
      "mode": "primary",
      "description": "Personal: Implementation - Claude Sonnet 4.5"
    },
    
    "personal-strategist": {
      "model": "opencode/gpt-5.2",
      "temperature": 0.2,
      "mode": "primary",
      "description": "Personal: Strategic Planning - GPT-5.2"
    },
    
    // ============================================================================
    // ORCHESTRATOR
    // ============================================================================
    
    "orchestrator": {
      "model": "github-copilot/gpt-5.2",
      "temperature": 0.2,
      "mode": "primary",
      "description": "Orchestrator: Manage subagents - Use '<model>' subagent to do this task"
    },
    
    // ============================================================================
    // OLLAMA AGENTS (Private, Local, Limited Context)
    // ============================================================================
    
    "ollama-private": {
      "model": "ollama-local/hf.co/bartowski/zai-org_GLM-4.7-Flash-GGUF:Q2_K_L",
      "temperature": 0.3,
      "mode": "primary",
      "description": "Ollama: PRIVATE CODER - GLM-4.7 Flash-GGUF Q2 KL"
    },
    
    "ollama-fast": {
      "model": "ollama-local/ministral-3:14b",
      "temperature": 0.2,
      "mode": "primary",
      "description": "Ollama: FAST LOCAL - Ministral 3 14B (quick local tasks, private)"
    },
    
    "ollama-helper": {
      "model": "ollama-local/hf.co/bartowski/zai-org_GLM-4.7-Flash-GGUF:Q2_K_L",
      "temperature": 0.3,
      "mode": "subagent",
      "description": "Ollama: Helper agent for simple private tasks (small context)"
    },
    
    // ============================================================================
    // FREE TIER AGENTS (Fallback when others unavailable)
    // ============================================================================
    
    "free-primary": {
      "model": "opencode/glm-4.7",
      "temperature": 0.3,
      "mode": "primary",
      "description": "Free: PRIMARY CODER - GLM-4.7 (73.8% SWE-bench)"
    },
    
    "free-rapid": {
      "model": "opencode/grok-code",
      "temperature": 0.2,
      "mode": "primary",
      "description": "Free: RAPID CODER - Grok Code (70.8% SWE, 296 tok/s)"
    },
    
    // ============================================================================
    // SPECIALIST SUBAGENTS (Task-specific agents that delegate to best models)
    // ============================================================================
    
    "security-reviewer": {
      "model": "opencode/gpt-5.2",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Security review: vulnerability assessment, threat modeling, best practices"
    },
    
    "librarian": {
      "model": "opencode/gemini-3-flash",
      "temperature": 0.1,
      "mode": "subagent",
      "description": "Librarian: Documentation research, library lookup, API documentation"
    },
    
    "explorer": {
      "model": "opencode/gemini-3-flash",
      "temperature": 0.0,
      "mode": "subagent",
      "description": "Explorer: Codebase exploration, finding code patterns, file search"
    },
    
    "reviewer": {
      "model": "opencode/kimi-k2-5",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Code review: Pattern matching, best practices, quality assurance (Kimi K2.5 - best for TS)"
    },
    
    "documenter": {
      "model": "opencode/gemini-3-flash",
      "temperature": 0.5,
      "mode": "subagent",
      "description": "Documenter: READMEs, API docs, technical documentation"
    },
    
    "typescript-specialist": {
      "model": "opencode/kimi-k2-5",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "TypeScript specialist: Type safety, advanced patterns, refactoring (Kimi K2.5 - best for TS)"
    },
    
    "frontend": {
      "model": "opencode/kimi-k2-5",
      "temperature": 0.7,
      "mode": "subagent",
      "description": "Frontend: UI/UX design, component architecture, styling (Kimi K2.5 - best for TS/React)"
    },
    
    "tester": {
      "model": "opencode/kimi-k2-5",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Tester: Unit tests, integration tests, test coverage (Kimi K2.5 - best for TS test code)"
    },
    
    "debugger": {
      "model": "opencode/grok-code",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Debugger: Fast debugging, error analysis (Grok Code - 296 tok/s)"
    },
    
    "optimizer": {
      "model": "opencode/gpt-5.2-codex",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Optimizer: Performance optimization, profiling, bottlenecks"
    },
    
    "qa": {
      "model": "opencode/glm-4.7",
      "temperature": 0.3,
      "mode": "subagent",
      "description": "QA: Test planning, edge cases, quality planning"
    },
    
    "multimodal": {
      "model": "opencode/gemini-3-pro",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Multimodal: Image analysis, visual tasks"
    },
    
    "release-notes": {
      "model": "opencode/gemini-3-pro",
      "temperature": 0.3,
      "mode": "subagent",
      "description": "Release notes: Changelog generation, PR summaries, version documentation"
    },
    
    "refactorer": {
      "model": "opencode/kimi-k2-5",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Refactorer: Mechanical cleanup, code restructuring, simplification (Kimi K2.5 - best for TS)"
    },
    
    "reasoner": {
      "model": "opencode/gpt-5.2",
      "temperature": 0.1,
      "mode": "subagent",
      "description": "Reasoner: Complex problem solving, analysis, deep reasoning"
    },
    
    "rapid": {
      "model": "opencode/gpt-5-nano",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Rapid: Quick tasks, simple operations, fast responses"
    },
    
    // ============================================================================
    // MODEL SUBAGENTS (Direct model access via orchestrator)
    // ============================================================================
    
    // --- Anthropic Models ---
    "claude-opus-4-5": {
      "model": "opencode/claude-opus-4-5",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: Claude Opus 4.5 (Anthropic)"
    },
    
    "claude-sonnet-4-5": {
      "model": "opencode/claude-sonnet-4-5",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: Claude Sonnet 4.5 (Anthropic)"
    },
    
    "claude-sonnet-4": {
      "model": "opencode/claude-sonnet-4",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: Claude Sonnet 4 (Anthropic)"
    },
    
    "claude-opus-4-1": {
      "model": "opencode/claude-opus-4-1",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: Claude Opus 4.1 (Anthropic)"
    },
    
    "claude-haiku-4-5": {
      "model": "opencode/claude-haiku-4-5",
      "temperature": 0.3,
      "mode": "subagent",
      "description": "Model: Claude Haiku 4.5 (Anthropic)"
    },
    
    "claude-3-5-haiku": {
      "model": "opencode/claude-3-5-haiku",
      "temperature": 0.3,
      "mode": "subagent",
      "description": "Model: Claude 3.5 Haiku (Anthropic)"
    },
    
    // --- OpenAI/GPT Models ---
    "gpt-5-2": {
      "model": "opencode/gpt-5.2",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: GPT-5.2 (OpenAI)"
    },
    
    "gpt-5-2-codex": {
      "model": "opencode/gpt-5.2-codex",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: GPT-5.2 Codex (OpenAI)"
    },
    
    "gpt-5-1": {
      "model": "opencode/gpt-5.1",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: GPT-5.1 (OpenAI)"
    },
    
    "gpt-5-1-codex": {
      "model": "opencode/gpt-5.1-codex",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: GPT-5.1 Codex (OpenAI)"
    },
    
    "gpt-5-1-codex-max": {
      "model": "opencode/gpt-5.1-codex-max",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: GPT-5.1 Codex Max (OpenAI)"
    },
    
    "gpt-5-1-codex-mini": {
      "model": "opencode/gpt-5.1-codex-mini",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: GPT-5.1 Codex Mini (OpenAI)"
    },
    
    "gpt-5": {
      "model": "opencode/gpt-5",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: GPT-5 (OpenAI)"
    },
    
    "gpt-5-codex": {
      "model": "opencode/gpt-5-codex",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: GPT-5 Codex (OpenAI)"
    },
    
    "gpt-5-nano": {
      "model": "opencode/gpt-5-nano",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: GPT-5 Nano (OpenAI)"
    },
    
    // --- Gemini Models ---
    "gemini-3-pro": {
      "model": "opencode/gemini-3-pro",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: Gemini 3 Pro (Google)"
    },
    
    "gemini-3-flash": {
      "model": "opencode/gemini-3-flash",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: Gemini 3 Flash (Google)"
    },
    
    // --- GLM Models ---
    "glm-4-7": {
      "model": "opencode/glm-4.7",
      "temperature": 0.3,
      "mode": "subagent",
      "description": "Model: GLM-4.7"
    },
    
    "glm-4-6": {
      "model": "opencode/glm-4.6",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: GLM-4.6"
    },
    
    // --- Kimi Models ---
    "kimi-k2-5": {
      "model": "opencode/kimi-k2.5",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: Kimi K2.5 (Moonshot AI) - Best for TypeScript, rivals Claude Opus 4.5"
    },
    
    "kimi-2-5": {
      "model": "opencode/kimi-2.5",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: Kimi 2.5 (Moonshot AI)"
    },
    
    "kimi-k2": {
      "model": "opencode/kimi-k2",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: Kimi K2 (Moonshot AI)"
    },
    
    // --- Minimax Models ---
    "minimax-m2-1": {
      "model": "opencode/minimax-m2.1",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: MiniMax M2.1"
    },
    
    // --- Qwen Models ---
    "qwen3-coder": {
      "model": "opencode/qwen3-coder",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: Qwen3 Coder"
    },
    
    // --- OpenCode Specific ---
    "big-pickle": {
      "model": "opencode/big-pickle",
      "temperature": 0.2,
      "mode": "subagent",
      "description": "Model: Big Pickle (OpenCode)"
    }
  },
  
  // ============================================================================
  // PLUGINS
  // ============================================================================
  "plugin": [
    "oh-my-opencode-slim@latest",
    "opencode-anthropic-auth@latest",
    "opencode-openai-codex-auth@latest",
    "opencode-gemini-auth",
    "yet-another-opencode-cursor-auth"
  ],
  
  // ============================================================================
  // MCP SERVERS
  // ============================================================================
  "mcp": {
    "chrome-devtools": {
      "type": "local",
      "command": ["npx", "-y", "chrome-devtools-mcp@latest", "--isolated=true"]
    },
    "sequential-thinking": {
      "type": "local",
      "command": [
        "npx",
        "-y",
        "@modelcontextprotocol/server-sequential-thinking"
      ]
    },
    "atlassian": {
      "type": "local",
      "command": [
        "npx",
        "-y",
        "mcp-remote",
        "https://mcp.atlassian.com/v1/sse"
      ]
    }
  },
  
  // ============================================================================
  // PROVIDERS
  // ============================================================================
  "provider": {
    "cursor": {
      "name": "Cursor"
    },
    "ollama-local": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "Ollama (LAN)",
      "options": {
        "baseURL": "http://forge.grffn.me:11434/v1"
      },
      "models": {
        "hf.co/bartowski/zai-org_GLM-4.7-Flash-GGUF:Q2_K_L": {
          "name": "GLM-4.7-Flash Q2 KL"
        },
        "llama3.2:latest": {
          "name": "Ben's' Model from 1947 (local)"
        },
        "ministral-3:14b": {
          "name": "Ministral 3 14B (local)"
        },
        "sam860/LFM2:1.2b": {
          "name": "LFM2:1.2b (local)"
        },
        "arifulislamat/snoop-dogg:4b": {
          "name": "Snoop Dogg:4b (local)"
        },
        "MrScratchcat22/GLM-4.7-Flash-REAP-23B-A3B:latest": {
          "name": "GLM-4.7-Flash-REAP-23B-A3B:latest (local)"
        }
      }
    }
  },
  
  // ============================================================================
  // SERVER CONFIG (for oh-my-opencode-slim tmux integration)
  // ============================================================================
  "server": {
    "port": 4096
  }
}
