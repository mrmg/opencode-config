{"type":"user","timestamp":"2026-01-20T10:36:39.106Z","content":"Task: Verify whether using 'qwen3:0.6b' as the Ollama model identifier is likely valid and recommend minimal safe request parameters for prompt-enhancement usage alongside image generation.\n\nSpecifically:\n1) Is 'qwen3:0.6b' a plausible Ollama model identifier format? Advise to confirm exact string via `ollama ls`.\n2) Confirm typical memory footprint for ~0.6b (600M) model and whether it's safe to run alongside image-gen that uses GPUs. Note quantization considerations.\n3) Recommend minimal JSON request payload for /api/generate for prompt-enhancement (fields and recommended values: stream:false, max_tokens, temperature, top_p) that minimize memory and latency.\n4) Any warnings or startup checks to add (eg. `ollama ls` check, or server-side test request) before enabling the feature in production.\n\nReturn concise actionable guidance and a sample request body. Keep it short."}
